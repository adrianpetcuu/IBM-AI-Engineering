# ğŸ“Š Regresie LogisticÄƒ

Regresia logisticÄƒ este un model de Ã®nvÄƒÈ›are automatÄƒ supravegheatÄƒ folosit pentru **clasificare binarÄƒ** (ex: spam vs. non-spam, boalÄƒ vs. sÄƒnÄƒtos, etc.).

---

## ğŸ§  Ce este Regresia LogisticÄƒ?

Este un algoritm statistic care estimeazÄƒ **probabilitatea** ca o observaÈ›ie sÄƒ aparÈ›inÄƒ uneia dintre cele douÄƒ clase posibile, folosind o funcÈ›ie logisticÄƒ (sigmoid).

---

## ğŸ“ˆ Formula

Modelul porneÈ™te de la o combinaÈ›ie liniarÄƒ:

z = wâ‚€ + wâ‚Â·xâ‚ + wâ‚‚Â·xâ‚‚ + ... + wâ‚™Â·xâ‚™

Se aplicÄƒ funcÈ›ia **sigmoid**:

Å· = Ïƒ(z) = 1 / (1 + e^(-z))

Aici:
- `Å·` este probabilitatea ca exemplul sÄƒ aparÈ›inÄƒ clasei pozitive (`1`)
- `wâ‚€` este bias-ul (interceptul)
- `wáµ¢` sunt coeficienÈ›ii (greutÄƒÈ›ile) asociaÈ›i fiecÄƒrei caracteristici `xáµ¢`

---

## ğŸ” Clasificare

DupÄƒ ce se calculeazÄƒ `Å·`, se aplicÄƒ un prag (`threshold`) pentru clasificare:

Å· â‰¥ 0.5 â†’ Clasa 1
Å· < 0.5 â†’ Clasa 0


Acest prag poate fi ajustat Ã®n funcÈ›ie de problemÄƒ.

---

## ğŸ§ª FuncÈ›ia de pierdere

Se foloseÈ™te **log-loss** (pierdere logaritmicÄƒ / entropie Ã®ncruciÈ™atÄƒ):

Loss = - [ yÂ·log(Å·) + (1 - y)Â·log(1 - Å·) ]


Pentru Ã®ntreg setul de date, se ia media pe toate exemplele.

---

## ğŸ“‰ Optimizare

- Se foloseÈ™te **Gradient Descent** pentru a ajusta coeficienÈ›ii `wáµ¢` astfel Ã®ncÃ¢t sÄƒ minimizeze funcÈ›ia de pierdere.
- Algoritmul este iterativ È™i se opreÈ™te cÃ¢nd convergenÈ›a este atinsÄƒ.

---

## âœ… Avantaje

- Simplu È™i eficient
- UÈ™or de interpretat
- Bun pentru probleme binare
- Performant pe seturi de date liniare

---

## âŒ LimitÄƒri

- Nu funcÈ›ioneazÄƒ bine cÃ¢nd relaÈ›ia dintre date nu este liniarÄƒ
- Sensibil la outlieri
- Nu suportÄƒ Ã®n mod nativ clasificarea multi-clasÄƒ (se poate extinde cu **One-vs-Rest**)

---

## ğŸ“¦ Implementare Ã®n Python (cu `scikit-learn`)

```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# X: caracteristici, y: etichete binare
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = LogisticRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)

print(f"AcurateÈ›ea modelului: {acc:.2f}")


