# ğŸ“Š Evaluarea modelelor de regresie & Random Forest

Acest ghid rezumÄƒ teoria esenÈ›ialÄƒ pentru evaluarea modelelor de **regresie** È™i, Ã®n particular, a unui **Random Forest Regressor** pe un set de date precum *California Housing*.

---

## 1) Setarea experimentului

- ÃmpÄƒrÈ›irea datelor Ã®n **train/test** pentru a estima performanÈ›a realÄƒ.  
- Alegerea unui **model de regresie** (Ã®n exemplul nostru Random Forest).  
- Compararea performanÈ›ei pe **train** È™i **test** pentru a identifica supraÃ®nvÄƒÈ›area (overfitting).  

---

## 2) Metrici esenÈ›iale de evaluare (regresie)

| Metrica | Ce mÄƒsoarÄƒ | ObservaÈ›ii |
|---------|------------|------------|
| **MAE (Mean Absolute Error)** | Eroarea medie Ã®n valoare absolutÄƒ | InterpretabilÄƒ Ã®n unitÄƒÈ›ile È›intei; mai robustÄƒ la outlieri decÃ¢t MSE |
| **MSE (Mean Squared Error)** | Media erorilor pÄƒtrate | PenalizeazÄƒ puternic erorile mari; sensibilÄƒ la outlieri |
| **RMSE (Root Mean Squared Error)** | RÄƒdÄƒcina pÄƒtratÄƒ a MSE | Ãn aceleaÈ™i unitÄƒÈ›i cu È›inta; comparabilÄƒ cu MAE |
| **RÂ² (Coefficient of Determination)** | ProporÈ›ia varianÈ›ei È›intei explicatÄƒ de model | 1 = perfect, 0 â‰ˆ model de medie, poate fi negativ pe test |

ğŸ”‘ **Reguli simple:**  
- **Mai mic** e mai bine pentru MAE, MSE, RMSE.  
- **Mai mare** e mai bine pentru RÂ² (atenÈ›ie la diferenÈ›e mari Ã®ntre train È™i test â†’ overfitting).  

---

## 3) Analiza distribuÈ›iei È›intei

- PloteazÄƒ histograma valorilor È›intÄƒ pentru a verifica **asimetria (skewness)**.  
- DacÄƒ distribuÈ›ia este foarte dezechilibratÄƒ, erorile pot fi distorsionate.  
- TransformÄƒrile logaritmice sau Box-Cox pot ajuta la reducerea skewness-ului.  

---

## 4) Diagnosticare vizualÄƒ

### a) Actual vs Predicted
- Scatter plot Ã®ntre valorile reale È™i cele prezise.  
- DacÄƒ punctele sunt apropiate de linia diagonalÄƒ â†’ predicÈ›ii bune.  
- Devieri sistematice de la linie â†’ bias al modelului.  

### b) Reziduuri (y_true âˆ’ y_pred)
- **HistogramÄƒ**: ar trebui sÄƒ fie centratÄƒ pe 0; cozi lungi sugereazÄƒ outlieri.  
- **Reziduuri vs. valori reale**: dacÄƒ existÄƒ pattern-uri (de ex. creÈ™tere cu valoarea È›intei), modelul are bias dependent de magnitudinea È›intei.  

---

## 5) ImportanÈ›a caracteristicilor (Feature Importance)

- Random Forest poate calcula cÃ¢t de importante sunt variabilele pentru predicÈ›ii.  
- Rezultatul se prezintÄƒ ca procentaj pentru fiecare variabilÄƒ.  
- **AtenÈ›ie**: ImportanÈ›ele nu implicÄƒ **cauzalitate**. DacÄƒ douÄƒ variabile sunt corelate, importanÈ›a poate fi Ã®mpÄƒrÈ›itÄƒ Ã®ntre ele.  

---

## 6) Random Forest â€“ bune practici

### Parametri importanÈ›i
- **n_estimators**: numÄƒrul de arbori (mai mulÈ›i â†’ stabilitate, dar cost computaÈ›ional mai mare).  
- **max_depth**: limiteazÄƒ adÃ¢ncimea arborilor (reduce overfitting).  
- **min_samples_leaf** / **min_samples_split**: impun regularizare suplimentarÄƒ.  
- **max_features**: nr. de variabile candidate la fiecare split (de obicei sqrt sau log2).  

### RecomandÄƒri
- Nu necesitÄƒ **scalarea datelor**.  
- FuncÈ›ioneazÄƒ bine cu **relaÈ›ii neliniare** È™i interacÈ›iuni Ã®ntre variabile.  
- FoloseÈ™te **validare Ã®ncruciÈ™atÄƒ** pentru alegerea parametrilor.  
- VerificÄƒ stabilitatea rezultatelor prin rulÄƒri repetate (schimbÄƒ seed-ul).  

---

## 7) Raport de evaluare â€“ checklist

1. **Config experiment**: Ã®mpÄƒrÈ›irea datelor, model ales, parametri folosiÈ›i.  
2. **Metrici pe test**: MAE, MSE, RMSE, RÂ² (comparÄƒ cu train).  
3. **Grafice utile**:  
   - Actual vs Predicted  
   - Histograma reziduurilor  
   - Reziduuri vs. valori reale  
   - Feature Importances  
4. **Interpretare**:  
   - Identificarea biasului È™i a varianÈ›ei.  
   - Subestimarea sau supraestimarea anumitor intervale de valori.  
   - Care variabile par cele mai influente.  
5. **PaÈ™i urmÄƒtori**:  
   - Optimizarea parametrilor.  
   - TransformÄƒri de variabile (dacÄƒ existÄƒ skewness).  
   - AnalizÄƒ suplimentarÄƒ a outlierilor.  

---

## 8) Exemple de concluzii

- **PerformanÈ›Äƒ**: raportarea numericÄƒ (ex: â€RÂ² = 0.82 pe testâ€).  
- **DiagnozÄƒ**: modelul subestimeazÄƒ valorile mari (casele cele mai scumpe).  
- **ImportanÈ›e**: venitul median È™i locaÈ›ia geograficÄƒ sunt factori majori.  
- **ÃmbunÄƒtÄƒÈ›iri**: tuning parametri, adÄƒugare de features derivate, transformarea È›intei.  

---

## 9) Capcane frecvente

- **Data leakage**: nu introduce informaÈ›ii viitoare Ã®n setul de antrenare.  
- **Overfitting**: diferenÈ›Äƒ mare Ã®ntre performanÈ›a pe train È™i test.  
- **Interpretare greÈ™itÄƒ**: feature importance â‰  cauzalitate.  
- **DistribuÈ›ii diferite**: dacÄƒ train È™i test provin din surse diferite, performanÈ›a scade Ã®n realitate.  

---

âœ… **Ideea centralÄƒ**: Evaluarea unui model de regresie nu se face cu o singurÄƒ metricÄƒ, ci prin combinarea **indicatorilor numerici**, a **graficelor de diagnosticare** È™i a **analizei critice** a rezultatelor.
