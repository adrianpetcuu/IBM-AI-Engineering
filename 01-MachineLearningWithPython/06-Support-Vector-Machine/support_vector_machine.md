# ğŸ’» Support Vector Machines (SVM)

## ğŸ” Ce este SVM?

**SVM (Support Vector Machine)** este un algoritm de Ã®nvÄƒÈ›are supervizatÄƒ folosit pentru **clasificare** È™i **regresie**. Scopul sÄƒu este sÄƒ gÄƒseascÄƒ o **linie de separare optimÄƒ** (sau un hiperplan Ã®n spaÈ›ii multidimensionale) care **maximizeazÄƒ marginea** Ã®ntre clase.

---

## âœ³ï¸ Cum funcÈ›ioneazÄƒ?

1. SVM cautÄƒ acel **hiperplan** care separÄƒ clasele cu **cea mai mare distanÈ›Äƒ** faÈ›Äƒ de cele mai apropiate puncte de fiecare clasÄƒ (numite **vectori de suport**).
2. DacÄƒ datele nu sunt liniar separabile, SVM foloseÈ™te o tehnicÄƒ numitÄƒ **kernel trick** pentru a le proiecta Ã®ntr-un spaÈ›iu mai mare unde devin separabile.

---

## ğŸ§  Tipuri de SVM

- **SVC (Support Vector Classification)** â€“ pentru clasificare
- **SVR (Support Vector Regression)** â€“ pentru regresie

---

## ğŸ§ª Kernel-uri disponibile

| Kernel      | Descriere                                  | Utilizare tipicÄƒ               |
|-------------|---------------------------------------------|--------------------------------|
| linear      | linie dreaptÄƒ sau hiperplan                 | cÃ¢nd datele sunt liniar separabile |
| poly        | polinomial                                  | pentru relaÈ›ii neliniare mai simple |
| rbf (gaussian) | radial basis function (default)         | majoritatea problemelor neliniare |
| sigmoid     | funcÈ›ie sigmoid                            | asemÄƒnÄƒtor cu reÈ›ele neuronale |

---

## âœ… Avantaje

- FuncÈ›ioneazÄƒ bine Ã®n **spaÈ›ii cu dimensiuni mari**
- Eficient cÃ¢nd numÄƒrul de caracteristici > numÄƒrul de eÈ™antioane
- **Flexibil** prin utilizarea de kernel-uri
- Robust la overfitting (Ã®n cazul datelor curate)

---

## âŒ Dezavantaje

- Mai lent pe seturi de date foarte mari
- PerformanÈ›a scade dacÄƒ datele sunt foarte zgomotoase
- NecesitÄƒ **scalarea caracteristicilor** (standardizare)

---

## ğŸ§ª Cod exemplu (SVM pentru clasificare)

```python
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix

# ÃncÄƒrcare date
iris = datasets.load_iris()
X = iris.data
y = iris.target

# Standardizare
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ÃmpÄƒrÈ›ire Ã®n train/test
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Model SVM cu kernel RBF
clf = SVC(kernel='rbf', C=1.0, gamma='scale')
clf.fit(X_train, y_train)

# PredicÈ›ii
y_pred = clf.predict(X_test)

# Evaluare
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))
```

## ğŸ“Œ Parametri importanÈ›i Ã®n SVC

| Parametru | Descriere |
|-----------|-----------|
| `C`       | Controlul overfitting-ului. Valori mari â†’ overfit, valori mici â†’ subfit. |
| `kernel`  | Tipul de funcÈ›ie kernel folosit (`linear`, `rbf`, `poly`, `sigmoid`). |
| `gamma`   | Definirea influenÈ›ei fiecÄƒrui punct de date Ã®n cazul kernel-ului RBF. |

---

### ğŸ¯ CÃ¢nd sÄƒ foloseÈ™ti SVM?

- Pentru **clasificare binarÄƒ** sau **multi-clasÄƒ**, cÃ¢nd datele sunt **curate** È™i **nu extrem de numeroase**.
- Ãn probleme de **bioinformaticÄƒ**, **clasificare de text**, **recunoaÈ™tere facialÄƒ** etc.
- CÃ¢nd alte modele (**Logistic Regression**, **KNN**) nu oferÄƒ performanÈ›Äƒ bunÄƒ.

---

### ğŸ“š NotÄƒ

SVM este un algoritm **clasic**, dar **extrem de puternic**.  
Ãn ciuda apariÈ›iei multor modele moderne, el rÄƒmÃ¢ne competitiv pentru **seturi de date mici È™i medii**, **bine prelucrate**.
