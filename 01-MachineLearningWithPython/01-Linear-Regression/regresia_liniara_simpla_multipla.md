# ğŸ“˜ README â€“ Regresie LiniarÄƒ SimplÄƒ È™i MultiplÄƒ

## ğŸ” Ce este regresia liniarÄƒ?
Regresia liniarÄƒ este o tehnicÄƒ de Ã®nvÄƒÈ›are automatÄƒ supravegheatÄƒ folositÄƒ pentru a prezice o variabilÄƒ dependentÄƒ continuÄƒ (`y`) pe baza uneia sau mai multor variabile independente (`X`). Modelul presupune o relaÈ›ie liniarÄƒ Ã®ntre aceste variabile.

---

## ğŸ“ˆ 1. Regresie LiniarÄƒ SimplÄƒ
**Scop:** Prezice o valoare continuÄƒ pe baza unei singure caracteristici (variabilÄƒ independentÄƒ).

**Model matematic:**  
`y = bâ‚€ + bâ‚ * x`

**Unde:**  
- `y` este valoarea prezisÄƒ  
- `x` este caracteristica (input)  
- `bâ‚€` este interceptul (bias)  
- `bâ‚` este coeficientul de regresie (pantÄƒ)  

**Avantaje:**  
- Simplu de implementat È™i Ã®nÈ›eles  
- Eficient pentru seturi de date mici  

**Dezavantaje:**  
- Poate subestima relaÈ›iile complexe  
- Nu capteazÄƒ curbe sau relaÈ›ii neliniare  

**Exemplu cod Python:**  
```python
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X, y) 
```

## ğŸ“Š 2. Regresie LiniarÄƒ MultiplÄƒ

**Scop:** Prezice o valoare continuÄƒ pe baza mai multor caracteristici (inputuri).

**Model matematic:**  
`y = bâ‚€ + bâ‚xâ‚ + bâ‚‚xâ‚‚ + ... + bâ‚™xâ‚™`

**Unde:**  
- `y` este valoarea prezisÄƒ  
- `xâ‚, xâ‚‚, ..., xâ‚™` sunt caracteristicile independente  
- `bâ‚€` este interceptul (bias)  
- `bâ‚, bâ‚‚, ..., bâ‚™` sunt coeficienÈ›ii pentru fiecare variabilÄƒ  

**Avantaje:**  
- Permite Ã®ncorporarea mai multor factori  
- Poate oferi predicÈ›ii mai precise  

**Dezavantaje:**  
- Presupune relaÈ›ii liniare Ã®ntre toate variabilele  
- Poate duce la overfitting dacÄƒ sunt prea multe variabile  

**Exemplu cod Python:**
```python
from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X, y)
```

---

## ğŸ§® 3. Regresie PolinomialÄƒ

**Scop:** Extinde regresia liniarÄƒ pentru a capta relaÈ›ii neliniare.

**Model matematic (grad 2):**  
`y = bâ‚€ + bâ‚x + bâ‚‚xÂ²`

**Avantaje:**  
- Mai precisÄƒ pentru relaÈ›ii curbilinii  
- UÈ™or de implementat cu `scikit-learn`

**Dezavantaje:**  
- Prone to overfitting la grade Ã®nalte  
- NecesitÄƒ transformarea manualÄƒ a caracteristicilor

**Exemplu cod Python:**
```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)
model = LinearRegression().fit(X_poly, y)
```

---

## ğŸ“Š 4. Evaluarea modelului (metode comune):

| FuncÈ›ie                  | Ce face                                                                 | Cod Python                                                              |
|--------------------------|--------------------------------------------------------------------------|-------------------------------------------------------------------------|
| `train_test_split()`     | Ãmparte datele Ã®n seturi de antrenare/testare                            | `from sklearn.model_selection import train_test_split`                 |
| `mean_squared_error()`   | Eroarea pÄƒtraticÄƒ medie Ã®ntre valori reale È™i prezise                    | `from sklearn.metrics import mean_squared_error`                       |
| `r2_score()`             | ProporÈ›ia variabilitÄƒÈ›ii explicate de model                              | `from sklearn.metrics import r2_score`                                 |
| `mean_absolute_error()`  | Eroarea absolutÄƒ medie Ã®ntre valorile reale È™i cele prezise              | `from sklearn.metrics import mean_absolute_error`                      |
| `StandardScaler()`       | NormalizeazÄƒ datele (centrat È™i scalat la deviaÈ›ie standard unitarÄƒ)     | `from sklearn.preprocessing import StandardScaler`                     |

---

## ğŸ§  NotiÈ›e importante

- **RÂ² (R-squared):** Cu cÃ¢t este mai aproape de `1`, cu atÃ¢t modelul explicÄƒ mai bine variabilitatea din date.  
- **MSE (Mean Squared Error):** MÄƒsoarÄƒ eroarea pÄƒtraticÄƒ medie â€“ valori mai mici sunt mai bune.  
- **RMSE (Root Mean Squared Error):** RÄƒdÄƒcina pÄƒtratÄƒ a MSE â€“ exprimatÄƒ Ã®n aceleaÈ™i unitÄƒÈ›i ca È™i È›inta (`y`).  
- **Overfitting:** Modelul Ã®nvaÈ›Äƒ prea bine datele de antrenament, dar are performanÈ›Äƒ slabÄƒ pe date noi.  
- **Underfitting:** Modelul este prea simplu pentru a capta structura realÄƒ a datelor.

---

## ğŸ”§ Exemple de aplicaÈ›ii

- ğŸ“Š Prezicerea preÈ›urilor imobiliare (folosind regresie liniarÄƒ multiplÄƒ)  
- ğŸ’¼ Estimarea salariului pe baza anilor de experienÈ›Äƒ (regresie simplÄƒ)  
- ğŸ›’ Estimarea cererii de produse Ã®n funcÈ›ie de preÈ› È™i sezon (regresie multiplÄƒ)  

---



